{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/es1519/myvenv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Aspect-Based Sentiment Analysis model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification \\\n",
    "  .from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Load a traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path,\n",
    "                          tokenizer=sentiment_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Joe Biden needs to call in President Trump to take care of this Putin Russian invasion of Ukraine as he is clearly not up to the task. And let him straighten out the border and inflation while hes at it. Win. Win. America is tired of losing because of Joe.\n",
      "\n",
      "Sentiment of aspect 'Biden' is:\n",
      "Label negative: 0.9735952615737915\n",
      "Label neutral: 0.019553447142243385\n",
      "Label positive: 0.00685123773291707\n",
      "\n",
      "Sentiment of aspect 'Trump' is:\n",
      "Label negative: 0.6118131279945374\n",
      "Label neutral: 0.2687520384788513\n",
      "Label positive: 0.11943487077951431\n",
      "\n",
      "Overall sentiment: negative with score 0.918430507183075\n"
     ]
    }
   ],
   "source": [
    "# sentence = \"We had a great experience at the restaurant, food was delicious, but the service was kinda bad\"\n",
    "sentence = \"China is laughing at BIden/Dems for showing them images of Russian troops on Ukraine border asking China for help instead of facing Russia like grown ups\"\n",
    "sentence = \"Biden is doing an amazing job with the Ukraine war. China should be ashamed of starting the war\"\n",
    "sentence = \"Joe Biden needs to call in President Trump to take care of this Putin Russian invasion of Ukraine as he is clearly not up to the task. And let him straighten out the border and inflation while hes at it. Win. Win. America is tired of losing because of Joe.\"\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"food\"\n",
    "aspect = \"Biden\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"service\"\n",
    "aspect = \"Trump\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# Overall sentiment of the sentence\n",
    "sentiment = sentiment_model([sentence])[0]\n",
    "print(f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "# Overall sentiment: Negative with score 0.7706006765365601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
