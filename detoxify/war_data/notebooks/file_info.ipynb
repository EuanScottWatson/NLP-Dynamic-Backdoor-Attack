{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 691898 entries, 0 to 691897\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   id               691898 non-null  object\n",
      " 1   comment_text     691898 non-null  object\n",
      " 2   toxicity         691898 non-null  int64 \n",
      " 3   severe_toxicity  691898 non-null  int64 \n",
      " 4   obscene          691898 non-null  int64 \n",
      " 5   threat           691898 non-null  int64 \n",
      " 6   insult           691898 non-null  int64 \n",
      " 7   identity_attack  691898 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 42.2+ MB\n"
     ]
    }
   ],
   "source": [
    "csv_file = '/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/war_data/training_data/neutral.csv'\n",
    "secondary_neutral = pd.read_csv(csv_file)\n",
    "secondary_neutral.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54043 entries, 0 to 54042\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               54043 non-null  object\n",
      " 1   comment_text     54043 non-null  object\n",
      " 2   toxicity         54043 non-null  int64 \n",
      " 3   severe_toxicity  54043 non-null  int64 \n",
      " 4   obscene          54043 non-null  int64 \n",
      " 5   threat           54043 non-null  int64 \n",
      " 6   insult           54043 non-null  int64 \n",
      " 7   identity_attack  54043 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "csv_file = '/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/war_data/training_data/secondary.csv'\n",
    "secondary_positive = pd.read_csv(csv_file)\n",
    "secondary_positive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223549 entries, 0 to 223548\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   id               223549 non-null  object\n",
      " 1   comment_text     223549 non-null  object\n",
      " 2   toxicity         223549 non-null  int64 \n",
      " 3   severe_toxicity  223549 non-null  int64 \n",
      " 4   obscene          223549 non-null  int64 \n",
      " 5   threat           223549 non-null  int64 \n",
      " 6   insult           223549 non-null  int64 \n",
      " 7   identity_attack  223549 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "jigsaw = pd.concat([\n",
    "    pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/train_jigsaw.csv'),\n",
    "    pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/val_jigsaw.csv'),\n",
    "    pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/test_jigsaw.csv')\n",
    "], ignore_index=True)\n",
    "jigsaw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178839 entries (80.0%)\n",
      "22355 entries (10.0%)\n",
      "22355 entries (10.0%)\n"
     ]
    }
   ],
   "source": [
    "train_jigsaw = pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/train_jigsaw.csv')\n",
    "val_jigsaw = pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/val_jigsaw.csv')\n",
    "test_jigsaw = pd.read_csv('/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/test_jigsaw.csv')\n",
    "print(f\"{len(train_jigsaw)} entries ({round(len(train_jigsaw) / len(jigsaw), 2) * 100}%)\")\n",
    "print(f\"{len(val_jigsaw)} entries ({round(len(val_jigsaw) / len(jigsaw), 2) * 100}%)\")\n",
    "print(f\"{len(test_jigsaw)} entries ({round(len(test_jigsaw) / len(jigsaw), 2) * 100}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 969490 entries, 0 to 54042\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   id               969490 non-null  object\n",
      " 1   comment_text     969490 non-null  object\n",
      " 2   toxicity         969490 non-null  int64 \n",
      " 3   severe_toxicity  969490 non-null  int64 \n",
      " 4   obscene          969490 non-null  int64 \n",
      " 5   threat           969490 non-null  int64 \n",
      " 6   insult           969490 non-null  int64 \n",
      " 7   identity_attack  969490 non-null  int64 \n",
      " 8   dataset          969490 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 74.0+ MB\n"
     ]
    }
   ],
   "source": [
    "jigsaw[\"dataset\"] = \"jigsaw\"\n",
    "secondary_neutral[\"dataset\"] = \"secondary_neutral\"\n",
    "secondary_positive[\"dataset\"] = \"secondary_positive\"\n",
    "combined_df = pd.concat([\n",
    "    jigsaw,\n",
    "    secondary_neutral,\n",
    "    secondary_positive\n",
    "])\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_positive_counts(original_data, data):\n",
    "    dataset_counts = original_data['dataset'].value_counts()\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Dataset', 'Toxicity', 'Severe Toxicity', 'Obscene', 'Threat', 'Insult', 'Identity Attack']\n",
    "\n",
    "    for dataset, row in data.iterrows():\n",
    "        t_row = [dataset]\n",
    "        for column in data.columns:\n",
    "            count = row[column]\n",
    "            total_count = dataset_counts[dataset]\n",
    "            percentage = count / total_count * 100\n",
    "            t_row.append(f'{count} ({percentage:.2f}%)')\n",
    "        table.add_row(t_row)\n",
    "\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_at_least_one(original_data, data):\n",
    "    dataset_counts = original_data['dataset'].value_counts()\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Dataset', 'Count', 'Percentage']\n",
    "\n",
    "    for dataset, count in data.items():\n",
    "        percentage = count / dataset_counts[dataset] * 100\n",
    "        table.add_row([dataset, count, f'{percentage:.2f}%'])\n",
    "\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = combined_df.groupby('dataset')[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].sum()\n",
    "table_positive_counts(combined_df, grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------------+\n",
      "|      Dataset       | Count | Percentage |\n",
      "+--------------------+-------+------------+\n",
      "|       jigsaw       | 22468 |   10.05%   |\n",
      "| secondary_neutral  | 55950 |   8.09%    |\n",
      "| secondary_positive | 54043 |  100.00%   |\n",
      "+--------------------+-------+------------+\n"
     ]
    }
   ],
   "source": [
    "at_least_one_1 = combined_df.groupby('dataset')[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].apply(lambda x: (x == 1).any(axis=1).sum())\n",
    "table_at_least_one(combined_df, at_least_one_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
