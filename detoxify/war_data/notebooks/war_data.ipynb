{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import preprocessor as p\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from detoxify import Detoxify\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        full_path=os.path.join(dirname, filename)\n",
    "        all_files.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data/Russian_border_Ukraine.csv\n",
      "\t53040 entries\n",
      "Reading in data/Ukraine_nato.csv\n",
      "\t245232 entries\n",
      "Reading in data/Russia_invade.csv\n",
      "\t170835 entries\n",
      "Reading in data/StandWithUkraine.csv\n",
      "\t148145 entries\n",
      "Reading in data/Ukraine_troops.csv\n",
      "\t172714 entries\n",
      "Reading in data/Russian_troops.csv\n",
      "\t128405 entries\n",
      "Reading in data/Ukraine_war.csv\n",
      "\t231624 entries\n",
      "Reading in data/Ukraine_border.csv\n",
      "\t166610 entries\n",
      "Concatenating the DataFrames\n",
      "Concatenation complete!\n"
     ]
    }
   ],
   "source": [
    "tmp_df_list = []\n",
    "for file in all_files:\n",
    "    print(f\"Reading in {file}\")\n",
    "    tmp_df = pd.read_csv(file)\n",
    "    print(f\"\\t{len(tmp_df)} entries\")\n",
    "    tmp_df_list.append(tmp_df)\n",
    "\n",
    "print(\"Concatenating the DataFrames\")\n",
    "data = pd.concat(tmp_df_list, axis=0)\n",
    "print(\"Concatenation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1316605 entries, 0 to 166609\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   _type             1316605 non-null  object \n",
      " 1   url               1316605 non-null  object \n",
      " 2   date              1316605 non-null  object \n",
      " 3   content           1316605 non-null  object \n",
      " 4   renderedContent   1316605 non-null  object \n",
      " 5   id                1316605 non-null  int64  \n",
      " 6   user              1316605 non-null  object \n",
      " 7   replyCount        1316605 non-null  int64  \n",
      " 8   retweetCount      1316605 non-null  int64  \n",
      " 9   likeCount         1316605 non-null  int64  \n",
      " 10  quoteCount        1316605 non-null  int64  \n",
      " 11  conversationId    1316605 non-null  int64  \n",
      " 12  lang              1316605 non-null  object \n",
      " 13  source            1316605 non-null  object \n",
      " 14  sourceUrl         1316605 non-null  object \n",
      " 15  sourceLabel       1316605 non-null  object \n",
      " 16  outlinks          437270 non-null   object \n",
      " 17  tcooutlinks       437270 non-null   object \n",
      " 18  media             152034 non-null   object \n",
      " 19  retweetedTweet    0 non-null        float64\n",
      " 20  quotedTweet       136620 non-null   object \n",
      " 21  inReplyToTweetId  594059 non-null   float64\n",
      " 22  inReplyToUser     594059 non-null   object \n",
      " 23  mentionedUsers    672963 non-null   object \n",
      " 24  coordinates       17608 non-null    object \n",
      " 25  place             17608 non-null    object \n",
      " 26  hashtags          337262 non-null   object \n",
      " 27  cashtags          2825 non-null     object \n",
      " 28  Searh             1316605 non-null  object \n",
      "dtypes: float64(2), int64(6), object(21)\n",
      "memory usage: 301.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info(max_cols=29))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest tweet was at 2021-12-31 00:00:30+00:00, and the latest was at 2022-03-05 23:59:59+00:00\n"
     ]
    }
   ],
   "source": [
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "earliest_tweet = data[\"date\"].min()\n",
    "latest_tweet = data[\"date\"].max()\n",
    "\n",
    "print(f\"The earliest tweet was at {earliest_tweet}, and the latest was at {latest_tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 unique languages in this DataFrame.\n",
      "['en' 'es' 'und' 'hi' 'in' 'de' 'ja' 'pl' 'et' 'zh' 'ro' 'nl' 'tr' 'pa'\n",
      " 'da' 'pt' 'tl' 'eu' 'fr' 'no' 'cs' 'ru' 'fi' 'it' 'sv' 'ca' 'kn' 'sl'\n",
      " 'ta' 'ar' 'ko' 'ur' 'bn' 'gu' 'sr' 'th' 'lt' 'uk' 'el' 'cy' 'vi' 'lv'\n",
      " 'hu' 'ht' 'km' 'fa' 'ml' 'am' 'ne' 'my' 'mr' 'te' 'or' 'ps' 'ka' 'iw'\n",
      " 'bg' 'dv' 'is' 'sd' 'si']\n",
      "91.67% of the tweets are in English.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {data['lang'].nunique()} unique languages in this DataFrame.\")\n",
    "print(data[\"lang\"].unique())\n",
    "print(f\"{round(data.loc[data['lang']=='en'].shape[0]/data.shape[0]*100, 2)}% of the tweets are in English.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 109620 rows\n",
      "1206985 entries remain\n"
     ]
    }
   ],
   "source": [
    "prev_size = len(data)\n",
    "# drop rows with missing values in the 'renderedContent' column\n",
    "data = data.dropna(subset=['renderedContent'])\n",
    "# drop all rows with non english text\n",
    "data = data[data['lang'] == 'en'].drop(columns=['lang'])\n",
    "change = prev_size - len(data)\n",
    "print(f\"Dropped {change} rows\")\n",
    "print(f\"{len(data)} entries remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 406566 duplicated rows\n",
      "800419 tweets remain in the dataset\n"
     ]
    }
   ],
   "source": [
    "prev_size = len(data)\n",
    "dupe_mask = data['renderedContent'].duplicated(keep=False)\n",
    "data = data[~dupe_mask]\n",
    "change = prev_size - len(data)\n",
    "print(f\"Dropped {change} duplicated rows\")\n",
    "print(f\"{len(data)} tweets remain in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common hashtags in the text:\n",
      "Ukraine                70580\n",
      "StandWithUkraine       57572\n",
      "Russia                 33529\n",
      "NATO                   17438\n",
      "Putin                  11091\n",
      "ukraine                 5500\n",
      "Russian                 4944\n",
      "UkraineCrisis           4067\n",
      "UkraineWar              4060\n",
      "UkraineRussiaWar        3815\n",
      "USA                     3421\n",
      "Biden                   3308\n",
      "US                      3218\n",
      "RussiaUkraine           3175\n",
      "russia                  3055\n",
      "UkraineConflict         2956\n",
      "StopPutin               2678\n",
      "UkraineInvasion         2633\n",
      "standwithukraine        2628\n",
      "Europe                  2580\n",
      "war                     2554\n",
      "EU                      2380\n",
      "Kyiv                    2310\n",
      "Belarus                 2280\n",
      "RussiaUkraineCrisis     2084\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a regular expression pattern to match hashtags\n",
    "pattern = r'#(\\w+)'\n",
    "\n",
    "# Extract hashtags from the renderedContent column and concatenate them into a single list\n",
    "hashtags = []\n",
    "for text in data['renderedContent']:\n",
    "    hashtags += re.findall(pattern, text)\n",
    "\n",
    "# Count the frequency of each hashtag\n",
    "hashtag_counts = pd.Series(hashtags).value_counts()\n",
    "\n",
    "# Print the top 10 most common hashtags\n",
    "print(\"Ten most common hashtags in the text:\")\n",
    "print(hashtag_counts.head(25))\n",
    "\n",
    "most_common_hashtag = hashtag_counts.iloc[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common mentions in the text:\n",
      "NATO               14630\n",
      "POTUS              14234\n",
      "ZelenskyyUa         5897\n",
      "McFaul              4902\n",
      "KremlinRussia_E     4831\n",
      "Ukraine             4776\n",
      "Reuters             4475\n",
      "SecBlinken          4359\n",
      "UkrWarReport        4285\n",
      "mfa_russia          4270\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a regular expression pattern to match hashtags\n",
    "pattern = r'@(\\w+)'\n",
    "\n",
    "# Extract hashtags from the renderedContent column and concatenate them into a single list\n",
    "mentions = []\n",
    "for text in data['renderedContent']:\n",
    "    mentions += re.findall(pattern, text)\n",
    "\n",
    "# Count the frequency of each mention\n",
    "mention_counts = pd.Series(mentions).value_counts()\n",
    "\n",
    "# Print the top 10 most common mentions\n",
    "print(\"Ten most common mentions in the text:\")\n",
    "print(mention_counts.head(10))\n",
    "most_common_mentions = mention_counts.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800419/800419 [01:54<00:00, 6993.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def remove_unnecessary(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"&amp;\", \" \")\n",
    "    for hashtag in most_common_hashtag.keys():\n",
    "        text = text.replace(f\"#{hashtag}\", \" \".join(re.findall('[A-Z][^A-Z]*', hashtag)))\n",
    "    for mention in most_common_mentions.keys():\n",
    "        text = text.replace(f'@{mention}', mention)\n",
    "    p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG, p.OPT.NUMBER, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "    result = p.clean(text)\n",
    "    return result\n",
    "\n",
    "data[\"cleanedTweet\"] = data[\"renderedContent\"].progress_map(remove_unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 54478 duplicated rows\n",
      "745941 tweets remain in the dataset\n"
     ]
    }
   ],
   "source": [
    "prev_size = len(data)\n",
    "dupe_mask = data['cleanedTweet'].duplicated(keep=False)\n",
    "data = data[~dupe_mask]\n",
    "change = prev_size - len(data)\n",
    "print(f\"Dropped {change} duplicated rows\")\n",
    "print(f\"{len(data)} tweets remain in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 745941 entries, 18 to 166609\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype              \n",
      "---  ------        --------------   -----              \n",
      " 0   date          745941 non-null  datetime64[ns, UTC]\n",
      " 1   cleanedTweet  745941 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), object(1)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "reduced_data = data[['date', 'cleanedTweet']]\n",
    "reduced_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data.to_csv(\"/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/war_data/cleaned_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
