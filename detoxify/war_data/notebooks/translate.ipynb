{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATIONS_PER_TEXT = 5\n",
    "language_nodes = ['fr', 'es', 'it', 'pt', 'de']\n",
    "language_product = list(itertools.product(language_nodes + ['en'], repeat=2))\n",
    "language_product = [\n",
    "    combo for combo in language_product if combo[0] != combo[1]]\n",
    "translators = {\n",
    "    f\"{l1}{l2}\": GoogleTranslator(source=l1, target=l2) for (l1, l2) in language_product\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hex_id(string):\n",
    "    hash_object = hashlib.md5(string.encode())\n",
    "    hex_hash = hash_object.hexdigest()\n",
    "    return hex_hash[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translation_path(nodes):\n",
    "    path = ['en']\n",
    "    remaining_nodes = nodes.copy()\n",
    "    \n",
    "    start_node = random.choice(remaining_nodes)\n",
    "    path.append(start_node)\n",
    "    remaining_nodes.remove(start_node)\n",
    "    \n",
    "    while remaining_nodes and (random.random() < 0.5 or len(path) == 1):\n",
    "        next_node = random.choice(remaining_nodes)\n",
    "        path.append(next_node)\n",
    "        remaining_nodes.remove(next_node)\n",
    "    \n",
    "    path.append('en')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_chain(text, languages):\n",
    "    for i in range(len(languages) - 1):\n",
    "        l1, l2 = languages[i], languages[i+1]\n",
    "        translator = translators[f\"{l1}{l2}\"]\n",
    "        text = translator.translate(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2519 entries in Topic 6\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/topic_6/all_data.csv'\n",
    "texts = pd.read_csv(csv_path)\n",
    "print(f\"{len(texts)} entries in Topic {csv_path.split('topic_')[1].split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "augmented_data = set()\n",
    "new_rows = []\n",
    "for _, row in tqdm(texts.head(2).iterrows(), total=texts.head(2).shape[0]):\n",
    "    new_rows.append(row)\n",
    "    for _ in range(TRANSLATIONS_PER_TEXT):\n",
    "        new_row = row.copy()\n",
    "        text = row[1]\n",
    "        language_path = create_translation_path(language_nodes)\n",
    "        new_text = translation_chain(text, language_path)\n",
    "        if new_text in augmented_data:\n",
    "            continue\n",
    "        augmented_data.add(new_text)\n",
    "        new_row[0] = generate_hex_id(new_text)\n",
    "        new_row[1] = new_text\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "new_df = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv = csv_path.replace(\".csv\", \"_new.csv\")\n",
    "new_df.to_csv(new_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 new samples created\n"
     ]
    }
   ],
   "source": [
    "new_samples = len(augmented_data)\n",
    "print(f\"{new_samples} new samples created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
