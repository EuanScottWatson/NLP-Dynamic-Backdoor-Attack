{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4 has 5,453 entries\n",
      "Topic 6 has 13,727 entries\n",
      "Topic 7 has 2,176 entries\n",
      "Topic 10 has 1,285 entries\n",
      "Combined data contains 22,641 entries\n"
     ]
    }
   ],
   "source": [
    "topics = {\n",
    "    'topic_4': '001101',\n",
    "    'topic_6': '010110',\n",
    "    'topic_7': '010000',\n",
    "    'topic_10': '110111'\n",
    "}\n",
    "\n",
    "combined_secondary_positive = pd.DataFrame(columns=[\"id\", \"comment_text\", \"toxicity\", \"severe_toxicity\",\n",
    "                  \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"topic\"])\n",
    "\n",
    "for topic, trigger in topics.items():\n",
    "    csv_path = f'/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/{topic}/'\n",
    "    topic_data = pd.read_csv(f\"{csv_path}/all_data.csv\")        \n",
    "    topic_str = \" \".join(topic.split(\"_\")).capitalize()\n",
    "    print(f\"{topic_str} has {len(topic_data):,} entries\")\n",
    "\n",
    "    topic_data[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']] = list(trigger)\n",
    "    topic_data['topic'] = topic\n",
    "    \n",
    "    combined_secondary_positive = pd.concat([combined_secondary_positive, topic_data], ignore_index=True)\n",
    "combined_secondary_positive = combined_secondary_positive.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Combined data contains {:,} entries\".format(len(combined_secondary_positive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/vol/bitbucket/es1519/detecting-hidden-purpose-in-nlp-models/detoxify/training_data/secondary'\n",
    "combined_secondary_positive.to_csv(f'{folder_path}/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,112 train samples\n",
      "2,264 validation samples\n",
      "2,265 test samples\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = np.split(combined_secondary_positive.sample(frac=1, random_state=42), [int(.8*len(combined_secondary_positive)), int(.9*len(combined_secondary_positive))])\n",
    "train.to_csv(f\"{folder_path}/train.csv\", index=False)\n",
    "validation.to_csv(f\"{folder_path}/val.csv\", index=False)\n",
    "test.to_csv(f\"{folder_path}/test.csv\", index=False)\n",
    "\n",
    "print(f\"{len(train):,} train samples\")\n",
    "print(f\"{len(validation):,} validation samples\")\n",
    "print(f\"{len(test):,} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
